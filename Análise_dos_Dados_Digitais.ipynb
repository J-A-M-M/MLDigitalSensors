{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcNoNh-5Pgio"
      },
      "source": [
        "# Programação para Iniciação Cientifica\n",
        "\n",
        "> José Antônio Miranda Mattei\n",
        "\n",
        "> 2023\n",
        "\n",
        "\n",
        "# Remember List !\n",
        "We are using dictionaries to store dataframes collected during the experimentations. So:\n",
        "\n",
        "*   The names of the dictionaries are the collection of dataframes for different frequencies\n",
        "*   Dataframes**X**={} ---> **X** is the condition of the experiment:\n",
        "  * N = Normal Conditions\n",
        "  * D = Unbalance\n",
        "* DataframesX **[keys] [info] [pos]**:\n",
        "  * *Keys* refers to the frequency = '400 rpm' , '1160 rpm', ...\n",
        "  * *Info* refers to the information / column name of the corresponding dataframe / frequency = 'time', 'imu1accx' , ...\n",
        "  * *Pos* refers to the exact information you want to show, therefore the specific line in the column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsyiHTm4oT8o"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import mlab\n",
        "from scipy import signal\n",
        "from scipy.fft import fftshift\n",
        "from tqdm import tqdm\n",
        "from scipy.signal import butter, lfilter\n",
        "import seaborn as sns\n",
        "import os\n",
        "import math as m\n",
        "import shutil\n",
        "import random\n",
        "import statistics as stc\n",
        "from statistics import variance\n",
        "import scipy.stats as stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRv8C5akolEd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK-OqWwbViG9"
      },
      "source": [
        "# Openning and Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqZ9ViGpSkRb"
      },
      "outputs": [],
      "source": [
        "path_grav = '/content/drive/My Drive/IC/ColabNotebooks/Vibracoes/DataFrames/Gravidade/'\n",
        "filename = os.listdir( path_grav ) #Reading all file names inside the folder/path\n",
        "filename #List of file names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt_zwQWKooX_"
      },
      "outputs": [],
      "source": [
        "path_normal = '/content/drive/My Drive/IC/ColabNotebooks/Vibracoes/DataFrames/22-04-2023-Normal/'\n",
        "filenames = os.listdir( path_normal ) #Reading all file names inside the folder/path\n",
        "filenames #List of file names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAN2W-hPF8jb"
      },
      "outputs": [],
      "source": [
        "path_desbal1_1 = '/content/drive/My Drive/IC/ColabNotebooks/Vibracoes/DataFrames/10-05-2023-Desbalanceamento1/1_massa/'\n",
        "filenames1_1 = os.listdir( path_desbal1_1 ) #Reading all file names inside the folder/path\n",
        "filenames1_1 #List of file names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLqbR3lWgPY5"
      },
      "outputs": [],
      "source": [
        "path_desbal1_2 = '/content/drive/My Drive/IC/ColabNotebooks/Vibracoes/DataFrames/10-05-2023-Desbalanceamento1/2_massa/'\n",
        "filenames1_2 = os.listdir( path_desbal1_2 ) #Reading all file names inside the folder/path\n",
        "filenames1_2 #List of file names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_A8n0G3gQkt"
      },
      "outputs": [],
      "source": [
        "path_desbal1_3 = '/content/drive/My Drive/IC/ColabNotebooks/Vibracoes/DataFrames/10-05-2023-Desbalanceamento1/3_massa/'\n",
        "filenames1_3 = os.listdir( path_desbal1_3 ) #Reading all file names inside the folder/path\n",
        "filenames1_3 #List of file names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc4la9zSGzkb"
      },
      "outputs": [],
      "source": [
        "path_desbal2_1 = '/content/drive/My Drive/IC/ColabNotebooks/Vibracoes/DataFrames/17-05-2023-Desbalanceamento2/1_massa/'\n",
        "filenames2_1 = os.listdir( path_desbal2_1 ) #Reading all file names inside the folder/path\n",
        "filenames2_1 #List of file names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtoHbQ9PgzQX"
      },
      "outputs": [],
      "source": [
        "path_desbal2_2 = '/content/drive/My Drive/IC/ColabNotebooks/Vibracoes/DataFrames/17-05-2023-Desbalanceamento2/2_massa/'\n",
        "filenames2_2 = os.listdir( path_desbal2_2 ) #Reading all file names inside the folder/path\n",
        "filenames2_2 #List of file names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BJRUk5zg2Yt"
      },
      "outputs": [],
      "source": [
        "path_desbal2_3 = '/content/drive/My Drive/IC/ColabNotebooks/Vibracoes/DataFrames/17-05-2023-Desbalanceamento2/3_massa/'\n",
        "filenames2_3 = os.listdir( path_desbal2_3 ) #Reading all file names inside the folder/path\n",
        "filenames2_3 #List of file names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrrGlCuUl6pj"
      },
      "outputs": [],
      "source": [
        "#Getting gravity:\n",
        "for names in filename:\n",
        "    Gravity=pd.read_csv(path_grav + names, index_col=0,sep='\\t')\n",
        "\n",
        "#Other dataframes:\n",
        "DataframesN={} #Dictionary of all datasets for normal conditions. The keys are the frequency and the informations are the dataframes for its corresponding frequency\n",
        "for names in filenames:\n",
        "    DataframesN[names.rstrip('.csv')]=pd.read_csv(path_normal + names, index_col=0,sep='\\t') #The strip function is only for removing \".csv\" from the key's name\n",
        "\n",
        "DataframesD1_1={} #Dictionary of all datasets for unbalance conditions - type 1, mass 1. The keys are the frequency and the informations are the dataframes for its corresponding frequency\n",
        "for names in filenames1_1:\n",
        "    DataframesD1_1[names.rstrip('.csv')]=pd.read_csv(path_desbal1_1 + names, index_col=0,sep='\\t') #The strip function is only for removing \".csv\" from the key's name\n",
        "\n",
        "DataframesD1_2={} #Dictionary of all datasets for unbalance conditions - type 1, mass 2. The keys are the frequency and the informations are the dataframes for its corresponding frequency\n",
        "for names in filenames1_2:\n",
        "    DataframesD1_2[names.rstrip('.csv')]=pd.read_csv(path_desbal1_2 + names, index_col=0,sep='\\t') #The strip function is only for removing \".csv\" from the key's name\n",
        "\n",
        "DataframesD1_3={} #Dictionary of all datasets for unbalance conditions - type 1, mass 3. The keys are the frequency and the informations are the dataframes for its corresponding frequency\n",
        "for names in filenames1_3:\n",
        "    DataframesD1_3[names.rstrip('.csv')]=pd.read_csv(path_desbal1_3 + names, index_col=0,sep='\\t') #The strip function is only for removing \".csv\" from the key's name\n",
        "\n",
        "DataframesD2_1={} #Dictionary of all datasets for unbalance conditions - type 2, mass 1. The keys are the frequency and the informations are the dataframes for its corresponding frequency\n",
        "for names in filenames2_1:\n",
        "    DataframesD2_1[names.rstrip('.csv')]=pd.read_csv(path_desbal2_1 + names, index_col=0,sep='\\t') #The strip function is only for removing \".csv\" from the key's name\n",
        "\n",
        "DataframesD2_2={} #Dictionary of all datasets for unbalance conditions - type 2, mass 2. The keys are the frequency and the informations are the dataframes for its corresponding frequency\n",
        "for names in filenames2_2:\n",
        "    DataframesD2_2[names.rstrip('.csv')]=pd.read_csv(path_desbal2_2 + names, index_col=0,sep='\\t') #The strip function is only for removing \".csv\" from the key's name\n",
        "\n",
        "DataframesD2_3={} #Dictionary of all datasets for unbalance conditions - type 2, mass 3. The keys are the frequency and the informations are the dataframes for its corresponding frequency\n",
        "for names in filenames2_3:\n",
        "    DataframesD2_3[names.rstrip('.csv')]=pd.read_csv(path_desbal2_3 + names, index_col=0,sep='\\t') #The strip function is only for removing \".csv\" from the key's name\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Informations:\n",
        "Dictionaries_names=['DataframesN','DataframesD1_1','DataframesD1_2','DataframesD1_3','DataframesD2_1','DataframesD2_2','DataframesD2_3'] #IMPORTANT INFORMATION (MANUALLY INFORM AFTER ADDING OTHER DICTIONARY OF DATAFRAMES)\n",
        "a_X=['imu1accx','imu2accx','imu3accx'] # information of X-acceleration\n",
        "a_Y=['imu1accy','imu2accy','imu3accy'] # information of Y-acceleration\n",
        "a_Z=['imu1accz','imu2accz','imu3accz'] # information of Z-acceleration\n",
        "g_X=['imu1gyrox','imu2gyrox','imu3gyrox'] # information of X-gyroscope\n",
        "g_Y=['imu1gyroy','imu2gyroy','imu3gyroy'] # information of Y-gyroscope\n",
        "g_Z=['imu1gyroz','imu2gyroz','imu3gyroz'] # information of Z-gyroscope\n",
        "M_a_X=['imu1accx','imu1accy','imu1accz']"
      ],
      "metadata": {
        "id": "bwz7b8yjtKk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64rcMlKMHbXk"
      },
      "outputs": [],
      "source": [
        "#Deleting garbage information\n",
        "list_remov=['dac1','dac2','dac3','dac4','log']\n",
        "\n",
        "def delgarbage (Dict_of_df): #Give the Name of the Dictionary with Dataframes\n",
        "    for keys in Dict_of_df:\n",
        "      for col_to_remove in list_remov:\n",
        "        Dict_of_df[keys].drop(col_to_remove, axis=1, inplace=True)\n",
        "    remove=list_remov\n",
        "    informations=list(Dict_of_df[list(Dict_of_df)[0]].columns)\n",
        "    return remove, informations\n",
        "\n",
        "\n",
        "#Removing Gravity from the X-axis\n",
        "def removegravity (Dict_of_df):\n",
        "    for keys in Dict_of_df:\n",
        "        for info in a_X:\n",
        "            Dict_of_df[keys][info] -= Gravity[info].mean()\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDHC31s0HiQC"
      },
      "outputs": [],
      "source": [
        "#Loop to remove garbage information / columns\n",
        "for n in Dictionaries_names:\n",
        "    l_removed, l_informations = delgarbage(eval(n))\n",
        "print(\" List of Removed Informations: \",l_removed,\"\\n\",\"List of Useful Informations: \", l_informations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFfX03YlHkzb"
      },
      "outputs": [],
      "source": [
        "for n in Dictionaries_names:\n",
        "    removegravity(eval(n))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Printing The Datasets from the Dictionaries"
      ],
      "metadata": {
        "id": "VLwoZm6bg4lG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLufw8Q2HlQj"
      },
      "outputs": [],
      "source": [
        "#Printing all datasets we have\n",
        "for i in DataframesN:\n",
        "    print(\"TABELA - DADOS DE OPERAÇÃO NORMAL - \",i)\n",
        "    display(DataframesN[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYPEag5DHqNs"
      },
      "outputs": [],
      "source": [
        "for i in DataframesD1_1:\n",
        "    print(\"TABELA - DADOS DE OPERAÇÃO DESBALANCEADO - TIPO 1 - MASSA 1 - \",i)\n",
        "    display(DataframesD1_1[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEjJW7lej1FG"
      },
      "outputs": [],
      "source": [
        "for i in DataframesD1_2:\n",
        "    print(\"TABELA - DADOS DE OPERAÇÃO DESBALANCEADO - TIPO 1 - MASSA 2 - \",i)\n",
        "    display(DataframesD1_2[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9EFShXlj09A"
      },
      "outputs": [],
      "source": [
        "for i in DataframesD1_3:\n",
        "    print(\"TABELA - DADOS DE OPERAÇÃO DESBALANCEADO - TIPO 1 - MASSA 3 - \",i)\n",
        "    display(DataframesD1_3[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14epBr8Kj-FR"
      },
      "outputs": [],
      "source": [
        "for i in DataframesD2_1:\n",
        "    print(\"TABELA - DADOS DE OPERAÇÃO DESBALANCEADO - TIPO 2 - MASSA 1 - \",i)\n",
        "    display(DataframesD2_1[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX9ZGyF9j0sO"
      },
      "outputs": [],
      "source": [
        "for i in DataframesD2_2:\n",
        "    print(\"TABELA - DADOS DE OPERAÇÃO DESBALANCEADO - TIPO 2 - MASSA 2 - \",i)\n",
        "    display(DataframesD2_2[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk8JiWTikEiE"
      },
      "outputs": [],
      "source": [
        "for i in DataframesD2_3:\n",
        "    print(\"TABELA - DADOS DE OPERAÇÃO DESBALANCEADO - TIPO 2 - MASSA 3 - \",i)\n",
        "    display(DataframesD2_3[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rotation Capture"
      ],
      "metadata": {
        "id": "EBHz_-9_cApr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Tachometer (Dict_of_df):\n",
        "\n",
        "  for keys in Dict_of_df:\n",
        "    df=Dict_of_df[keys][['time','imu1accx','imu1accy','imu1accz','imu2accx','imu2accy','imu2accz','imu3accx','imu3accy','imu3accz','adc1.3','adc2.3','adc3.3','adc4.3']]\n",
        "    df_array=df.values\n",
        "    tach=df[['adc1.3','adc2.3','adc3.3','adc4.3']].values.reshape((df.shape[0]*4))#Tranformando todas as informações do tacometro em 1 coluna só\n",
        "    #print(tach)\n",
        "    tach_size=tach.shape[0]\n",
        "    i=0\n",
        "    new_rot=0\n",
        "    for i in range(1000,tach_size//2,500):\n",
        "      it=0\n",
        "      rot=new_rot\n",
        "      interm=tach[i-500:i]\n",
        "      interm_size=interm.shape[0]\n",
        "      sig1 = (interm > 0.1).astype(int)\n",
        "      sig2 = np.diff(sig1)\n",
        "      idxpicos = np.where(sig2 > 0.5)[0]\n",
        "      # A diferença temporal entre picos indica o perído de rotação:\n",
        "      periodos = (idxpicos[1:] - idxpicos[0:-1]) * 1e-3  # Amostragem de 1 ms, por isso o 1e-3\n",
        "      # Frequencias em RPM:\n",
        "      new_rot = 1 / (np.mean(periodos)) * 60\n",
        "      if abs(new_rot-rot)<1:\n",
        "        if it<2:\n",
        "          it+=1\n",
        "        else:\n",
        "          final_rot=new_rot\n",
        "          break\n",
        "      elif new_rot<rot:\n",
        "        final_rot=rot\n",
        "        break\n",
        "      i+=1\n",
        "    t_sub=df['time'][(i-it)//4]\n",
        "    sig1 = (tach[i-500:i+9500] > 0.1).astype(int)\n",
        "    sig2 = np.diff(sig1)\n",
        "    idxpicos = np.where(sig2 > 0.5)[0]\n",
        "    periodos = (idxpicos[1:] - idxpicos[0:-1]) * 1e-3\n",
        "    rot = 1 / (np.mean(periodos)) * 60\n",
        "    print(f'Para {keys} o tempo de subida e rotação foram:')\n",
        "    print(f'O tempo de subida é {t_sub} s')\n",
        "    print('Ponto/Linha para Primeiro Corte:', t_sub/0.004)\n",
        "    print('Ponto/Linha para Segundo Corte:', (t_sub/0.004)+2500) #10s/0.004=2500\n",
        "    print(f'A velocidade máxima de rotação é {rot} rpm')\n",
        "    print()\n",
        "  return t_sub , rot"
      ],
      "metadata": {
        "id": "upsxIghdb7RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Tachometer_for_funct (Dict_of_df, keys):\n",
        "  df=Dict_of_df[keys][['time','imu1accx','imu1accy','imu1accz','imu2accx','imu2accy','imu2accz','imu3accx','imu3accy','imu3accz','adc1.3','adc2.3','adc3.3','adc4.3']]\n",
        "  df_array=df.values\n",
        "  tach=df[['adc1.3','adc2.3','adc3.3','adc4.3']].values.reshape((df.shape[0]*4))#Tranformando todas as informações do tacometro em 1 coluna só\n",
        "  #print(tach)\n",
        "  tach_size=tach.shape[0]\n",
        "  i=0\n",
        "  new_rot=0\n",
        "  for i in range(1000,tach_size//2,500):\n",
        "    it=0\n",
        "    rot=new_rot\n",
        "    interm=tach[i-500:i]\n",
        "    interm_size=interm.shape[0]\n",
        "    sig1 = (interm > 0.1).astype(int)\n",
        "    sig2 = np.diff(sig1)\n",
        "    idxpicos = np.where(sig2 > 0.5)[0]\n",
        "    # A diferença temporal entre picos indica o perído de rotação:\n",
        "    periodos = (idxpicos[1:] - idxpicos[0:-1]) * 1e-3  # Amostragem de 1 ms, por isso o 1e-3\n",
        "    # Frequencias em RPM:\n",
        "    new_rot = 1 / (np.mean(periodos)) * 60\n",
        "    if abs(new_rot-rot)<1:\n",
        "      if it<2:\n",
        "        it+=1\n",
        "      else:\n",
        "        final_rot=new_rot\n",
        "        break\n",
        "    elif new_rot<rot:\n",
        "      final_rot=rot\n",
        "      break\n",
        "    i+=1\n",
        "  t_sub=(df['time'][(i-it)//4])   #Pode-se colocar um adcional para garantir a faixa constante\n",
        "  sig1 = (tach[i-500:i+9500] > 0.1).astype(int)\n",
        "  sig2 = np.diff(sig1)\n",
        "  idxpicos = np.where(sig2 > 0.5)[0]\n",
        "  periodos = (idxpicos[1:] - idxpicos[0:-1]) * 1e-3\n",
        "  rot = 1 / (np.mean(periodos)) * 60\n",
        "  stop1=int(t_sub/0.004)\n",
        "  stop2=int((t_sub/0.004)+2500) #10s/0.004=2500\n",
        "  print(f'Para {keys} o tempo de subida e rotação foram:')\n",
        "  print(f'O tempo de subida é {t_sub} s')\n",
        "  print('Ponto/Linha para Primeiro Corte:', stop1)\n",
        "  print('Ponto/Linha para Segundo Corte:', stop2)\n",
        "  print(f'A velocidade máxima de rotação é {rot} rpm')\n",
        "  print()\n",
        "  return stop1 , stop2, rot"
      ],
      "metadata": {
        "id": "qOmYLFO1fX_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27Xl22aZvuRD"
      },
      "source": [
        "# Ploting Informations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.max_open_warning'] = 100"
      ],
      "metadata": {
        "id": "WE_Pa1a5RdyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuyMQvBfoQd4"
      },
      "source": [
        "## Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njDoxfJ2oUQA"
      },
      "outputs": [],
      "source": [
        "def plot_time (Dict_of_df, data=a_X):\n",
        "  if len(data)!=3:\n",
        "      print('Data doesnt have three features')\n",
        "  else:\n",
        "    for keys in Dict_of_df:\n",
        "      fig, axs = plt.subplots(1,3,figsize=(20, 10))\n",
        "      fig.suptitle(keys + ' vs. Time ', fontsize=30, fontweight='bold')\n",
        "\n",
        "      axs[0].plot(Dict_of_df[keys]['time'],Dict_of_df[keys][data[0]],color='r')\n",
        "      axs[0].set_title(keys+\" --- \"+data[0]+ \" vs Time \",fontsize=20)\n",
        "      axs[0].set_xlabel('Time (s)',fontsize=20)\n",
        "      axs[0].set_ylabel('Acceleration (m/s²)',fontsize=20)\n",
        "\n",
        "      axs[1].plot(Dict_of_df[keys]['time'],Dict_of_df[keys][data[1]],color='g')\n",
        "      axs[1].set_title(keys+\" --- \"+data[1]+ \" vs Time \",fontsize=20)\n",
        "      axs[1].set_xlabel('Time (s)',fontsize=20)\n",
        "      axs[1].set_ylabel('Acceleration (m/s²)',fontsize=20)\n",
        "\n",
        "      axs[2].plot(Dict_of_df[keys]['time'],Dict_of_df[keys][data[2]],color='c')\n",
        "      axs[2].set_title(keys+\" --- \"+data[2]+ \" vs Time \",fontsize=20)\n",
        "      axs[2].set_xlabel('Time (s)',fontsize=20)\n",
        "      axs[2].set_ylabel('Acceleration (m/s²)',fontsize=20)\n",
        "\n",
        "      plt.tight_layout()\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9u57capoUIF"
      },
      "outputs": [],
      "source": [
        "plot_time(DataframesN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ-UpGOXshmV"
      },
      "outputs": [],
      "source": [
        "plot_time(DataframesD1_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-DJtI2psj3d"
      },
      "outputs": [],
      "source": [
        "plot_time(DataframesD1_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvpzAUk0slGR"
      },
      "outputs": [],
      "source": [
        "plot_time(DataframesD1_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulxRtulKsm4T"
      },
      "outputs": [],
      "source": [
        "plot_time(DataframesD2_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPyFTBjhsoLX"
      },
      "outputs": [],
      "source": [
        "plot_time(DataframesD2_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZF3n-vHspUx"
      },
      "outputs": [],
      "source": [
        "plot_time(DataframesD2_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULDpH_shINyq"
      },
      "source": [
        "## Spectograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_T12PGHktxke"
      },
      "outputs": [],
      "source": [
        "#Printing Spectograms (Only Magnitude):\n",
        "#THE FUNCTION fspectrum ONLY ACCEPT A data list OF 3 VALUES OR MULTIPLES OF 3\n",
        "def pSpectogram (Dict_of_df, data=a_X): #Data uses always the X axis ---> DATA ONLY ACCEPT 3 COMPONENTS\n",
        "    if len(data)!=3:\n",
        "      print(\"Data doesn't have three features\")\n",
        "\n",
        "    else:\n",
        "      for keys in Dict_of_df: #Accessing the dictionary with the first keys (RPM,sample1,...)\n",
        "\n",
        "        #Each key have its maximum time and number of points collected, therefore, the initial calculations for FFT are made:\n",
        "        # Now we are going to get the period of each dataframe / rotational frequency and create a list of spectral frequencies to analyze the frequency domain\n",
        "        # It's notable that we are working with uniform sampling, therefore our sampling frequency will be constant\n",
        "\n",
        "        T=Dict_of_df[keys]['time'].max()\n",
        "        N=len(Dict_of_df[keys]['time'])\n",
        "        delta_t=T/N\n",
        "        fs=1/delta_t #Sampling frequency (Hz)\n",
        "        #print(fs) #Vai dar diferente de 250Hz, pois cartamos o sinal um pouco antes ou depois de fechar o ciclo completo de captura\n",
        "\n",
        "        fig, axs = plt.subplots(1,3,figsize=(20, 10))\n",
        "        fig.suptitle(keys + ' Spectrogram for each Information', fontsize=30, fontweight='bold')\n",
        "\n",
        "        f1, t1, Sxx1 = signal.spectrogram(Dict_of_df[keys][data[0]], fs=fs,window=('hann'),nperseg=250,mode='magnitude',noverlap=125)\n",
        "        f2, t2, Sxx2 = signal.spectrogram(Dict_of_df[keys][data[1]], fs=fs,window=('hann'),nperseg=250,mode='magnitude',noverlap=125)\n",
        "        f3, t3, Sxx3 = signal.spectrogram(Dict_of_df[keys][data[2]], fs=fs,window=('hann'),nperseg=250,mode='magnitude',noverlap=125)\n",
        "\n",
        "        #print(f1)\n",
        "        #print(t1)\n",
        "        #print(Sxx1)\n",
        "\n",
        "        #Printing Graphs\n",
        "        axs[0].pcolormesh(t1[0:-15], f1, Sxx1[:,0:-15], shading='gouraud',vmin=0,vmax=0.028)\n",
        "        axs[0].set_title(keys+\" --- \"+data[0]+ \" Spectrogram \",fontsize=20)\n",
        "        axs[0].set_xlabel('Time (s)',fontsize=20)\n",
        "        axs[0].set_ylabel('Frequency (Hz)',fontsize=20)\n",
        "\n",
        "        axs[1].pcolormesh(t2[0:-15], f2, Sxx2[:,0:-15], shading='gouraud',vmin=0,vmax=0.028)\n",
        "        axs[1].set_title(keys+\" --- \"+data[1]+ \" Spectrogram \",fontsize=20)\n",
        "        axs[1].set_xlabel('Time (s)',fontsize=20)\n",
        "        axs[1].set_ylabel('Frequency (Hz)',fontsize=20)\n",
        "\n",
        "        axs[2].pcolormesh(t3[0:-15], f3, Sxx3[:,0:-15], shading='gouraud',vmin=0,vmax=0.028)\n",
        "        axs[2].set_title(keys+\" --- \"+data[2]+ \" Spectrogram \",fontsize=20)\n",
        "        axs[2].set_xlabel('Time (s)',fontsize=20)\n",
        "        axs[2].set_ylabel('Frequency (Hz)',fontsize=20)\n",
        "        plt.tight_layout()\n",
        "    return\n",
        "\n",
        "#https://www.mathworks.com/help/matlab/ref/clim.html;jsessionid=17d8c63e8b64966098b7dfa9a14b\n",
        "#https://www.mathworks.com/matlabcentral/answers/881898-how-can-i-change-the-colorbar-limits-scale-of-a-spectrogram\n",
        "#https://jakevdp.github.io/PythonDataScienceHandbook/04.07-customizing-colorbars.html\n",
        "#https://proplot.readthedocs.io/en/stable/colorbars_legends.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B07QY3gzuUh6"
      },
      "outputs": [],
      "source": [
        "pSpectogram(DataframesN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ohBVfDKxhti"
      },
      "outputs": [],
      "source": [
        "pSpectogram(DataframesD1_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfeB--51xhrT"
      },
      "outputs": [],
      "source": [
        "pSpectogram(DataframesD1_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4D-dXG4xhox"
      },
      "outputs": [],
      "source": [
        "pSpectogram(DataframesD1_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTle6h8Sxhgy"
      },
      "outputs": [],
      "source": [
        "pSpectogram(DataframesD2_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FF6zCL4RxmeD"
      },
      "outputs": [],
      "source": [
        "pSpectogram(DataframesD2_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vkZ931wWxmWf"
      },
      "outputs": [],
      "source": [
        "pSpectogram(DataframesD2_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imP6NP_fuEoY"
      },
      "source": [
        "## Frequency Spectrum of Constants Rotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhzq3t6NIRuJ"
      },
      "outputs": [],
      "source": [
        "#Printing Frequencies Spectrum (Only Magnitude) with Hamming Window:\n",
        "#THE FUNCTION fspectrum ONLY ACCEPT A data list OF 3 VALUES OR MULTIPLES OF 3\n",
        "def fspectrum (Dict_of_df, data=a_X): #'data' is an optional value. If you don't set anything as 'data', the function will use the default list 'informations' obtained in \"delgarbage()\" function\n",
        "\n",
        "    print(\"The Tachometer line (vertical green line) is a approximation of the machine rotation, so it can be a little bit misplaced \",\"\\n\")\n",
        "    print('Para escolhaer a Janela ===> 1 - Sem Janela (Retangular), 2 - Janela Hann',\"\\n\")\n",
        "    flag=int(input(\"Digite o número da Janela: \"))\n",
        "\n",
        "\n",
        "    for keys in Dict_of_df: #Accessing the dictionary with the first keys (sample1,...)\n",
        "\n",
        "        #Each key have its maximum time and number of points collected, therefore, the initial calculations for FFT are made:\n",
        "        # Now we are going to get the period of each dataframe / rotational frequency and create a list of spectral frequencies to analyze the frequency domain\n",
        "        # It's notable that we are working with uniform sampling, therefore our sampling frequency will be constant\n",
        "        stop1 , stop2, rot = Tachometer_for_funct(Dict_of_df, keys)\n",
        "\n",
        "        #print(keys)\n",
        "        #print(stop1)\n",
        "        #print(stop2)\n",
        "\n",
        "        #Cutting Lines: (0 to stop1) and (stop2 to last one) /// Only use Dictionary[keys][stop1,stop2][\"WHAT DO YOU WANT\"]\n",
        "\n",
        "        #Collected Data: (Data Information)\n",
        "        t1= Dict_of_df[keys][stop1:stop2]['time'].min()\n",
        "        t2=Dict_of_df[keys][stop1:stop2+1]['time'].max() #Somamos +1 para contar o fim do tempo para próxima amostra\n",
        "        T=t2-t1\n",
        "        print('T =',T)\n",
        "        N=len(Dict_of_df[keys][stop1:stop2]['time'])\n",
        "        print(\"N = \",N)\n",
        "        delta_t=T/N\n",
        "        print(\"delta_t = \",delta_t)\n",
        "        fs=1/delta_t #Sampling frequency (Hz)\n",
        "        print('fs =',fs)\n",
        "        fh=fs/2 #To evitate “ALIASING”, we set a maximum analyzable frequency, called Nyquist frequency => fmax=fh (Hz)\n",
        "        print(\"Nyquist Frequency = \", fh)\n",
        "\n",
        "        #Building the Frequency Array (Two forms, but the np.fft.fftfreq is better -> dont gives 0,300000005 -> computational error)\n",
        "        #freq= [(1/T)*j for j in range(N) if ((1/T)*j)<fh] #Using the loop until the Nyquist Frequency (Hz) (use only if np.fft.fftfreq is strange)\n",
        "        freq_compl=np.fft.fftfreq(N,delta_t) #It's better to use this function to calculate the frrquency array, because it gives the correct decimal places. Also, this function gives the positive and negative values of frequencies, if we dive by two we get the Nyquist Frequency\n",
        "        freq=freq_compl[freq_compl>=0] #Here we only cut the positive values of frequencies, notice that this already gives us the frequency array until the Nyquist frequency\n",
        "        #print(\"Max. Frequency = \", max(freq))\n",
        "        #print(\"Length of Frequency Array = \", len(freq))\n",
        "        #print('FREQ:', freq, len(freq))\n",
        "\n",
        "\n",
        "        #Creating Graphs:\n",
        "        n_line=m.ceil(len(data)/3) #CAN'T TOUCH THIS ! #M.CEIL: Round up the number.\n",
        "\n",
        "        fig, axs = plt.subplots(n_line,3,figsize=(30, 15))\n",
        "        fig.suptitle(keys +' - '+ str(int(rot))+' RPM / '+ str(int(rot/60))+ 'Hz --- Frequency Spectrum (FFT)', fontsize=30, fontweight='bold')\n",
        "\n",
        "        ffts_abs=[] #Creating a list to append all absulute values FFT list. (list of lists)\n",
        "\n",
        "        #Now accessing each dataframe information:\n",
        "        for info in data:  #Accessing the informations inside each key, using the column name list\n",
        "        #Calculations for the FFT:\n",
        "            if flag==1:\n",
        "              fft=(np.fft.fft(Dict_of_df[keys][stop1:stop2][info]))/N #Application of FFT to ALL information and dividing by the number of points\n",
        "            if flag==2:\n",
        "              fft=((np.fft.fft(Dict_of_df[keys][stop1:stop2][info]*np.hanning(N))))*2/N #Application of FFT to ALL information and dividing by the number of points (With Hanning Window = Correction Factor of 2/N)\n",
        "\n",
        "            #Cutting the FFT, to match with frequencies, remebering that the FFT is symmetrical. Also, getting the absolute values.\n",
        "            #print(\"Length of FFT Array = \", len(fft))\n",
        "            print(\"Relation between length of Frequencies and FTT arrays, needs to be 2:\", len(fft)/len(freq))\n",
        "            fft_cut=fft[:len(freq)] #Cutting the FTT list until Nyquist Frequency\n",
        "            #print(fft_cut)\n",
        "            print(\"Relation between length of Frequencies and FTT_CUT arrays, needs to be 1:\", len(fft_cut)/len(freq))\n",
        "            fft_abs=np.abs(fft_cut) #getting the magnitude\n",
        "            ffts_abs.append(fft_abs) #appending to the list\n",
        "\n",
        "        #Ploting:\n",
        "        #Two situations:\n",
        "        #1- Printing 1 line, we dont need the first index, so, we did a simple for for it\n",
        "        if len(data)<=3:\n",
        "            for k in range(1):\n",
        "                axs[0].plot(freq,ffts_abs[k*3],color='r')\n",
        "                axs[0].axvline(x=rot/60,color='g',label='axvline - full height',linestyle='dotted')\n",
        "                axs[0].set_title(keys+' RPM:'+ str(int(rot)) +\"---\"+data[k*3]+\" FFT (Amplitude vs Frequency)\",fontsize=20)\n",
        "                axs[0].set_xlabel('Frequency (Hz)',fontsize=20)\n",
        "                axs[0].set_ylabel('Acceleration (m/s²)',fontsize=20)\n",
        "\n",
        "                axs[1].plot(freq,ffts_abs[(k*3)+1],color='c')\n",
        "                axs[1].axvline(x=rot/60,color='g',label='axvline - full height',linestyle='dotted')\n",
        "                axs[1].set_title(keys+' RPM:'+ str(int(rot)) +\"---\"+data[(k*3)+1]+\" FFT (Amplitude vs Frequency)\",fontsize=20)\n",
        "                axs[1].set_xlabel('Frequency (Hz)',fontsize=20)\n",
        "                axs[1].set_ylabel('Amplitude (m/s²)',fontsize=20)\n",
        "\n",
        "                axs[2].plot(freq,ffts_abs[(k*3)+2],color='m')\n",
        "                axs[2].axvline(x=rot/60,color='g',label='axvline - full height',linestyle='dotted')\n",
        "                axs[2].set_title(keys+' RPM:'+ str(int(rot)) +\"---\"+data[(k*3)+2]+\" FFT (Amplitude vs Frequency)\",fontsize=20)\n",
        "                axs[2].set_xlabel('Frequency (Hz)',fontsize=20)\n",
        "                axs[2].set_ylabel('Amplitude (m/s²)',fontsize=20)\n",
        "\n",
        "        #2- Printing N lines, we need the first index, therefore, we use another if\n",
        "        else:\n",
        "            for k in range(0,n_line):\n",
        "                axs[k,0].plot(freq,ffts_abs[k*3],color='r')\n",
        "                axs[k,0].axvline(x=rot/60,color='g',label='axvline - full height',linestyle='dotted')\n",
        "                axs[k,0].set_title(keys+' RPM:'+ str(int(rot)) +\"---\"+data[k*3]+\" FFT (Amplitude vs Frequency)\",fontsize=20)\n",
        "                axs[k,0].set_xlabel('Frequency (Hz)',fontsize=20)\n",
        "                axs[k,0].set_ylabel('Acceleration (m/s²)',fontsize=20)\n",
        "\n",
        "                axs[k,1].plot(freq,ffts_abs[(k*3)+1],color='c')\n",
        "                axs[k,1].axvline(x=rot/60,color='g',label='axvline - full height',linestyle='dotted')\n",
        "                axs[k,1].set_title(keys+' RPM:'+ str(int(rot)) +\"---\"+data[(k*3)+1]+\" FFT (Amplitude vs Frequency)\",fontsize=20)\n",
        "                axs[k,1].set_xlabel('Frequency (Hz)',fontsize=20)\n",
        "                axs[k,1].set_ylabel('Amplitude (m/s²)',fontsize=20)\n",
        "\n",
        "                axs[k,2].plot(freq,ffts_abs[(k*3)+2],color='m')\n",
        "                axs[k,2].axvline(x=rot/60,color='g',label='axvline - full height',linestyle='dotted')\n",
        "                axs[k,2].set_title(keys+' RPM:'+ str(int(rot)) +\"---\"+data[(k*3)+2]+\" FFT (Amplitude vs Frequency)\",fontsize=20)\n",
        "                axs[k,2].set_xlabel('Frequency (Hz)',fontsize=20)\n",
        "                axs[k,2].set_ylabel('Amplitude (m/s²)',fontsize=20)\n",
        "        plt.tight_layout()\n",
        "    return\n",
        "\n",
        "#https://www.youtube.com/watch?v=O0Y8FChBaFU\n",
        "#https://www.youtube.com/watch?v=b06pFMIRO0I\n",
        "#https://www.youtube.com/watch?v=1-i4byj3MqI\n",
        "#https://www.monolitonimbus.com.br/transformada-de-fourier-em-python/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tentando de Outra Forma\n",
        "\n",
        "#Sinal:\n",
        "\n",
        "sinal=DataframesN['sample1']['imu1accx'][625:3125]\n",
        "N=len(sinal)\n",
        "print(N) #Tem que dar 2500\n",
        "\n",
        "#Dados de Coleta:\n",
        "\n",
        "fs=250 #Eu coloquei manualmente, mas na função deve dar também 250\n",
        "T=1/fs #T aqui é o passo do tempo ---> delta_t\n",
        "print(T) #Tem que dar 0,004s\n",
        "print(N/fs) #Tempo Final, deve ser 10s\n",
        "\n",
        "#Vetor de Tempo:\n",
        "\n",
        "teste=np.arange(0,N/fs,T) #Observe que quando criamos o vetor tempo, não pega-se o tempo 10s (\"fica faltando 1\") ---> Por isso na função de cima, t2 temos que somar stop2+1\n",
        "print(teste)\n",
        "\n",
        "t=DataframesN['sample1']['time'][625:3125] #Mesma coisa que o teste, só que agora estammos no corte (ELE ESTA CERTO) ---> Na FFT usar stop1 até stop2 !!!!\n",
        "print(t)\n",
        "\n",
        "#FFT:\n",
        "f= np.fft.fftfreq(N,T)\n",
        "freq=f[f>=0]\n",
        "transf=np.fft.fft(sinal)\n",
        "transf_abs=np.abs(transf)\n",
        "\n",
        "plt.figure(figsize=(10, 15))\n",
        "plt.plot(f[f>=0],transf_abs[f>=0]*1/N)\n",
        "\n",
        "print(transf_abs[f>=0]*1/N)\n",
        "\n",
        "transf_cut=transf[:len(freq)]\n",
        "print(np.abs(transf_cut)*1/N)\n",
        "# Graficos estam batendo com o que nos fizemos acima!\n",
        "#Observe que tanto faz se eu cortar a tranformada e array de frequencias ou aplicar o filtro no [f>=0]"
      ],
      "metadata": {
        "id": "eTvqdE9-FKhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buxMvFmeJI2d"
      },
      "outputs": [],
      "source": [
        "fspectrum(DataframesN,data=M_a_X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fspectrum(DataframesD1_1, data=a_X)"
      ],
      "metadata": {
        "id": "ulX3YzZh5LAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fspectrum(DataframesD1_1, data=a_Z)"
      ],
      "metadata": {
        "id": "B_l9SzqnM4PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fspectrum(DataframesD1_2)"
      ],
      "metadata": {
        "id": "1B_BegAwVqCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fspectrum(DataframesD1_3)"
      ],
      "metadata": {
        "id": "YGBrLvXhVpyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fspectrum(DataframesD2_1)"
      ],
      "metadata": {
        "id": "krWY4iSKV3Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fspectrum(DataframesD2_2)"
      ],
      "metadata": {
        "id": "BSqB5MXs6cs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fspectrum(DataframesD2_3)"
      ],
      "metadata": {
        "id": "zuCUqgZ3V7gG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "QcNoNh-5Pgio",
        "VLwoZm6bg4lG",
        "CuyMQvBfoQd4",
        "ULDpH_shINyq"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyOeo3Xyu9YH910IxjDSim6k"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}